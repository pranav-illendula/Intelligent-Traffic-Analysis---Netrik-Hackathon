{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14633637,"sourceType":"datasetVersion","datasetId":9347735},{"sourceId":732439,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":558147,"modelId":570714}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics opencv-python -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:12:45.042430Z","iopub.execute_input":"2026-01-27T04:12:45.042708Z","iopub.status.idle":"2026-01-27T04:12:50.843268Z","shell.execute_reply.started":"2026-01-27T04:12:45.042675Z","shell.execute_reply":"2026-01-27T04:12:50.842432Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install lap","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:13:41.747325Z","iopub.execute_input":"2026-01-27T04:13:41.747926Z","iopub.status.idle":"2026-01-27T04:13:45.147403Z","shell.execute_reply.started":"2026-01-27T04:13:41.747892Z","shell.execute_reply":"2026-01-27T04:13:45.146485Z"}},"outputs":[{"name":"stdout","text":"Collecting lap\n  Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from lap) (2.0.2)\nDownloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: lap\nSuccessfully installed lap-0.5.12\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\nimport csv\n\n# =========================================\n# PATHS\n# =========================================\nVIDEO_PATH = \"/kaggle/input/video-traffic-1080/vehicles_stack_1080p.mp4\"\nCOCO_MODEL_PATH = \"yolov8s.pt\"\nAUTO_MODEL_PATH = \"/kaggle/input/auto-model-1/pytorch/default/1/best (1).pt\"\n\nOUTPUT_VIDEO = \"/kaggle/working/final_output_fixed_v1.mp4\"\nCSV_PATH = \"/kaggle/working/violations_v1.csv\"\n\n# =========================================\n# PARAMETERS (TUNABLE)\n# =========================================\nCOCO_VEHICLES = {\"car\", \"bus\", \"truck\", \"motorcycle\"}\n\nSTOP_LINE_Y_RATIO = 0.60\nSTOPPED_DIST_PX = 3\n\nFRONT_N = 4                     # âœ” only front vehicles\nRED_RATIO_THRESHOLD = 0.6       # âœ” % stopped â†’ RED\nGREEN_HOLD_FRAMES = 15          # âœ” green buffer\n\nQUEUE_DEPTH_RATIO = 0.35\nIOU_MATCH = 0.5\nCONF_MARGIN = 0.15\n\n# =========================================\n# LOAD MODELS\n# =========================================\ncoco_model = YOLO(COCO_MODEL_PATH)\nauto_model = YOLO(AUTO_MODEL_PATH)\n\n# =========================================\n# IOU FUNCTION\n# =========================================\ndef iou(a, b):\n    xA = max(a[0], b[0])\n    yA = max(a[1], b[1])\n    xB = min(a[2], b[2])\n    yB = min(a[3], b[3])\n    inter = max(0, xB - xA) * max(0, yB - yA)\n    areaA = (a[2]-a[0])*(a[3]-a[1])\n    areaB = (b[2]-b[0])*(b[3]-b[1])\n    return inter / (areaA + areaB - inter + 1e-6)\n\n# =========================================\n# VIDEO SETUP\n# =========================================\ncap = cv2.VideoCapture(VIDEO_PATH)\nfps = cap.get(cv2.CAP_PROP_FPS)\nW = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nH = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nSTOP_LINE_Y = int(H * STOP_LINE_Y_RATIO)\nQUEUE_DEPTH_PX = int(H * QUEUE_DEPTH_RATIO)\n\nout = cv2.VideoWriter(\n    OUTPUT_VIDEO,\n    cv2.VideoWriter_fourcc(*\"mp4v\"),\n    fps,\n    (W, H)\n)\n\n# =========================================\n# STATE\n# =========================================\nlast_front_y = {}\nwas_stopped = {}\nviolators = set()\n\nsignal_state = \"RED\"\ngreen_hold = 0\n\nviolation_count = 0\nviolation_log = []\nframe_idx = 0\n\n# =========================================\n# MAIN LOOP\n# =========================================\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    frame_idx += 1\n    time_sec = round(frame_idx / fps, 2)\n    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n    # -------- COCO DETECTION + TRACKING --------\n    coco_res = coco_model.track(\n        frame_rgb,\n        persist=True,\n        conf=0.4,\n        device=0,\n        verbose=False\n    )[0]\n\n    vehicle_boxes = []\n\n    if coco_res.boxes is not None:\n        for b in coco_res.boxes:\n            label = coco_res.names[int(b.cls)]\n            if label in COCO_VEHICLES and b.id is not None:\n                x1, y1, x2, y2 = map(int, b.xyxy[0])\n                vehicle_boxes.append([\n                    x1, y1, x2, y2,\n                    label,\n                    float(b.conf),\n                    int(b.id)\n                ])\n\n    # -------- AUTO RICKSHAW REFINEMENT --------\n    crops, offsets = [], []\n    for x1, y1, x2, y2, label, _, _ in vehicle_boxes:\n        if label in {\"car\", \"truck\"}:\n            crop = frame_rgb[y1:y2, x1:x2]\n            if crop.size > 0:\n                crops.append(crop)\n                offsets.append((x1, y1))\n\n    auto_res = auto_model.predict(\n        crops,\n        conf=0.25,\n        device=0,\n        verbose=False\n    ) if crops else []\n\n    for i, res in enumerate(auto_res):\n        if res.boxes is None:\n            continue\n        ox, oy = offsets[i]\n        for b in res.boxes:\n            ax1, ay1, ax2, ay2 = b.xyxy[0]\n            auto_box = (int(ox+ax1), int(oy+ay1), int(ox+ax2), int(oy+ay2))\n            for v in vehicle_boxes:\n                if iou(auto_box, v[:4]) >= IOU_MATCH and float(b.conf) > v[5] + CONF_MARGIN:\n                    v[4] = \"auto\"\n                    v[5] = float(b.conf)\n\n    # -------- SIGNAL INFERENCE (FIXED LOGIC) --------\n    behind = []\n    for _, _, _, y2, _, _, tid in vehicle_boxes:\n        if y2 < STOP_LINE_Y:\n            behind.append((tid, y2))\n\n    behind.sort(key=lambda x: STOP_LINE_Y - x[1])\n    front = behind[:FRONT_N]\n\n    stopped = 0\n    for tid, fy in front:\n        if tid in last_front_y:\n            if abs(fy - last_front_y[tid]) < STOPPED_DIST_PX:\n                stopped += 1\n\n    if green_hold > 0:\n        signal_state = \"GREEN\"\n        green_hold -= 1\n    else:\n        if len(front) > 0 and stopped / len(front) >= RED_RATIO_THRESHOLD:\n            signal_state = \"RED\"\n        else:\n            signal_state = \"GREEN\"\n            green_hold = GREEN_HOLD_FRAMES\n\n    # -------- QUEUE LENGTH --------\n    queue_ids = set()\n    for _, _, _, y2, _, _, tid in vehicle_boxes:\n        if tid in last_front_y:\n            stopped = abs(y2 - last_front_y[tid]) < STOPPED_DIST_PX\n            behind_stop = y2 < STOP_LINE_Y\n            in_zone = y2 > STOP_LINE_Y - QUEUE_DEPTH_PX\n            if stopped and behind_stop and in_zone:\n                queue_ids.add(tid)\n\n    queue_length = len(queue_ids)\n\n    # -------- VIOLATION CHECK + DRAW --------\n    for x1, y1, x2, y2, label, conf, tid in vehicle_boxes:\n        speed_px = 0\n        if tid in last_front_y:\n            speed_px = abs(y2 - last_front_y[tid])\n\n        if speed_px < STOPPED_DIST_PX:\n            was_stopped[tid] = True\n\n        crossed = (\n            tid in last_front_y and\n            last_front_y[tid] < STOP_LINE_Y and\n            y2 >= STOP_LINE_Y\n        )\n\n        if (\n            crossed and\n            signal_state == \"RED\" and\n            tid not in violators and\n            was_stopped.get(tid, False)\n        ):\n            violators.add(tid)\n            violation_count += 1\n\n            violation_log.append({\n                \"violation_id\": violation_count,\n                \"vehicle_id\": tid,\n                \"vehicle_type\": label,\n                \"time\": time_sec,\n                \"speed_px\": round(speed_px, 2),\n                \"queue_length\": queue_length,\n                \"signal_state\": signal_state\n            })\n\n        last_front_y[tid] = y2\n\n        color = (0,0,255) if tid in violators else (0,255,0)\n        cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n        cv2.putText(\n            frame,\n            f\"{label.upper()} ID:{tid}\",\n            (x1, max(25, y1-5)),\n            cv2.FONT_HERSHEY_SIMPLEX,\n            0.7,\n            color,\n            2\n        )\n\n    # -------- OVERLAYS --------\n    cv2.line(frame, (0, STOP_LINE_Y), (W, STOP_LINE_Y), (0,0,255), 3)\n    cv2.putText(frame, f\"SIGNAL: {signal_state}\", (30,40),\n                cv2.FONT_HERSHEY_SIMPLEX, 1.1,\n                (0,255,255) if signal_state==\"GREEN\" else (0,0,255), 3)\n\n    cv2.putText(frame, f\"QUEUE: {queue_length}\", (30,80),\n                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,0), 3)\n\n    cv2.putText(frame, f\"VIOLATIONS: {violation_count}\", (30,120),\n                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,0,255), 3)\n\n    out.write(frame)\n\n# =========================================\n# WRITE CSV\n# =========================================\nwith open(CSV_PATH, \"w\", newline=\"\") as f:\n    writer = csv.DictWriter(\n        f,\n        fieldnames=[\n            \"violation_id\",\n            \"vehicle_id\",\n            \"vehicle_type\",\n            \"time\",\n            \"speed_px\",\n            \"queue_length\",\n            \"signal_state\"\n        ]\n    )\n    writer.writeheader()\n    writer.writerows(violation_log)\n\ncap.release()\nout.release()\n\nprint(\"âœ… FIXED LOGIC PIPELINE COMPLETE\")\nprint(f\"ðŸŽ¥ Video: {OUTPUT_VIDEO}\")\nprint(f\"ðŸ“„ CSV: {CSV_PATH}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-27T04:45:46.302516Z","iopub.execute_input":"2026-01-27T04:45:46.302988Z","iopub.status.idle":"2026-01-27T04:52:09.931753Z","shell.execute_reply.started":"2026-01-27T04:45:46.302956Z","shell.execute_reply":"2026-01-27T04:52:09.930962Z"}},"outputs":[{"name":"stdout","text":"âœ… FIXED LOGIC PIPELINE COMPLETE\nðŸŽ¥ Video: /kaggle/working/final_output_fixed_v1.mp4\nðŸ“„ CSV: /kaggle/working/violations_v1.csv\n","output_type":"stream"}],"execution_count":4}]}